{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual synthetic data\n",
    "\n",
    "# Feature(s)\n",
    "X = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]).reshape(-1, 1)\n",
    "\n",
    "# Target\n",
    "y = np.array([1.1, 2.9, 3.7, 4.5, 5.2, 6.3, 7.5, 8.3, 9.2, 10.1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hold-out cross validation\n",
    "- Split the sample into 2 sets (typically, 70:30 OR 80:20)\n",
    "- Use the larger set for training\n",
    "- Use the smaller set for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual train-test split\n",
    "split_ratio = 0.8\n",
    "split_index = int(len(X) * split_ratio)\n",
    "\n",
    "X_train, X_test = X[:split_index], X[split_index:]\n",
    "y_train, y_test = y[:split_index], y[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "model = LinearRegression()\n",
    "\n",
    "# fit = find out the bias and the weights\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters \"learnt\" by the model\n",
    "print(\"bias = \", model.intercept_)\n",
    "print(\"weight = \", model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Metrics**\n",
    "1. ### **R-Square (R²)**\n",
    "\n",
    "The **R-Square (R²) score**, also called the **coefficient of determination**, is a statistical measure that indicates how well the independent variable(s) explain the variance in the dependent variable.\n",
    "\n",
    "#### **Formula:**\n",
    "$$\n",
    "R^2 = 1 - \\frac{SS_{res}}{SS_{tot}}\n",
    "$$\n",
    "Where:\n",
    "- $ SS_{res} $  = **Residual Sum of Squares (RSS)**  \n",
    "  $$\n",
    "  SS_{res} = \\sum (y_{true} - y_{pred})^2\n",
    "  $$\n",
    "  This represents the total squared differences between actual values ($y_{true}$ ) and predicted values ($y_{pred}$ ).\n",
    "\n",
    "- $ SS_{tot} $  = **Total Sum of Squares (TSS)**  \n",
    "  $$\n",
    "  SS_{tot} = \\sum (y_{true} - \\bar{y})^2\n",
    "  $$\n",
    "  This represents the squared differences between actual values ($y_{true}$ ) and the **mean** of actual values ($\\bar{y}$ ).\n",
    "\n",
    "### **Interpretation of R²**\n",
    "- **R² = 1:** Perfect fit (all data points lie on the regression line).\n",
    "- **R² = 0:** The model does not explain any variance in the dependent variable.\n",
    "- **R² < 0:** The model performs worse than a simple mean-based model (bad fit).\n",
    "\n",
    "### **Example Calculation**\n",
    "Let's assume we have:\n",
    "- **Actual values**: $ y_{true} = [3, 5, 7, 9] $ \n",
    "- **Predicted values**: $ y_{pred} = [2.8, 5.2, 6.8, 9.1] $ \n",
    "- **Mean of actual values**: $ \\bar{y} = (3+5+7+9)/4 = 6 $ \n",
    "\n",
    "Now, compute the sum of squares:\n",
    "\n",
    "1. **Compute:** $ SS_{res} $ \n",
    "   $$\n",
    "   (3 - 2.8)^2 + (5 - 5.2)^2 + (7 - 6.8)^2 + (9 - 9.1)^2\n",
    "   $$\n",
    "   $$\n",
    "   = (0.2)^2 + (-0.2)^2 + (0.2)^2 + (-0.1)^2 = 0.04 + 0.04 + 0.04 + 0.01 = 0.13\n",
    "   $$\n",
    "\n",
    "2. **Compute:** $ SS_{tot} $ \n",
    "   $$\n",
    "   (3 - 6)^2 + (5 - 6)^2 + (7 - 6)^2 + (9 - 6)^2\n",
    "   $$\n",
    "   $$\n",
    "   = (-3)^2 + (-1)^2 + (1)^2 + (3)^2 = 9 + 1 + 1 + 9 = 20\n",
    "   $$\n",
    "\n",
    "3. **Compute:** $ R^2 $ \n",
    "   $$\n",
    "   R^2 = 1 - \\frac{0.13}{20} = 1 - 0.0065 = 0.9935\n",
    "   $$\n",
    "\n",
    "**Conclusion**\n",
    "- The **R² score of 0.9935** means that **99.35% of the variance in the dependent variable is explained by the model**.\n",
    "- A high R² value indicates a strong model fit.\n",
    "\n",
    "\n",
    "\n",
    "2. **Mean Squared Error (MSE)**:\n",
    "   - Measures the average squared difference between actual and predicted values.\n",
    "   - A lower MSE indicates better performance.\n",
    "   - Formula:  \n",
    "     $$\n",
    "     MSE = \\frac{1}{n} \\sum (y_{true} - y_{pred})^2\n",
    "     $$\n",
    "   - `mean_squared_error(y_test, y_pred)`\n",
    "\n",
    " **Key Interpretations:**\n",
    "1. **Lower MSE = Better Fit**  \n",
    "   - A lower MSE indicates that the model's predictions are closer to the actual values, meaning better accuracy.\n",
    "\n",
    "2. **Higher MSE = Poor Fit**  \n",
    "   - A higher MSE suggests that the model's predictions deviate significantly from the actual values, indicating poor performance.\n",
    "\n",
    "3. **Squared Differences Impact**  \n",
    "   - Since errors are squared, larger errors contribute disproportionately more to the MSE. This makes MSE sensitive to large outliers.\n",
    "\n",
    "4. **Units of MSE**  \n",
    "   - MSE is expressed in the squared units of the dependent variable. For example, if predicting **house prices in dollars**, MSE would be in **square dollars ($²)**, which can be hard to interpret directly.\n",
    "\n",
    "5. **Comparing Models**  \n",
    "   - When comparing multiple models, the one with the **lower MSE** is usually preferred, assuming similar complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Calculating model accuracy\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy (R^2 Score): {r2:.4f}\")\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Model Accuracy (MSE): {mse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting a sample\n",
    "sample_value = np.array([[4.9]])\n",
    "predicted_value = model.predict(sample_value)\n",
    "print(f\"Predicted value for input {sample_value.flatten()[0]}: {predicted_value.flatten()[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot results\n",
    "plt.scatter(X_train, y_train, color='blue', label='Training Data')\n",
    "plt.scatter(X_test, y_test, color='red', label='Test Data')\n",
    "plt.scatter([sample_value], [predicted_value], color='purple', label='Sample Data')\n",
    "plt.plot(X, model.predict(X), color='green', linestyle='dashed', label='Regression Line')\n",
    "plt.legend()\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(\"Linear Regression\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_Beginner_WS",
   "language": "python",
   "name": "ml_beginner_ws"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
